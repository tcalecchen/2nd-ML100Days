{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZbsakGqKIIRv"
   },
   "source": [
    "作業\n",
    "\n",
    "礙於不是所有同學都有 GPU ，這邊的範例使用的是簡化版本的 ResNet，確保所有同學都能夠順利訓練!\n",
    "\n",
    "最後一天的作業請閱讀這篇非常詳盡的文章，基本上已經涵蓋了所有訓練　CNN 常用的技巧，請使用所有學過的訓練技巧，盡可能地提高 Cifar-10 的 test data 準確率，截圖你最佳的結果並上傳來完成最後一次的作業吧!\n",
    "\n",
    "另外這些技巧在 Kaggle 上也會被許多人使用，更有人會開發一些新的技巧，例如使把預訓練在 ImageNet 上的模型當成 feature extractor 後，再拿擷取出的特徵重新訓練新的模型，這些技巧再進階的課程我們會在提到，有興趣的同學也可以參考"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 38864,
     "status": "ok",
     "timestamp": 1565101847516,
     "user": {
      "displayName": "陳信榮",
      "photoUrl": "https://lh4.googleusercontent.com/-OFFdnL2yS4E/AAAAAAAAAAI/AAAAAAAABc8/1xp3cp3kugc/s64/photo.jpg",
      "userId": "09164636050182271119"
     },
     "user_tz": -480
    },
    "id": "_9PR0gR2UXCC",
    "outputId": "6f8837d9-73ba-4b12-e380-2e4ff07289d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2871,
     "status": "ok",
     "timestamp": 1565102684461,
     "user": {
      "displayName": "陳信榮",
      "photoUrl": "https://lh4.googleusercontent.com/-OFFdnL2yS4E/AAAAAAAAAAI/AAAAAAAABc8/1xp3cp3kugc/s64/photo.jpg",
      "userId": "09164636050182271119"
     },
     "user_tz": -480
    },
    "id": "pkxTpIewIEdv",
    "outputId": "d280a14d-f31a-41ae-a51a-05b5d97ef271"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'/content/drive/My Drive/resnet_builder.py'\n"
     ]
    }
   ],
   "source": [
    "!ls /content/drive/My\\ Drive/*.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2686,
     "status": "ok",
     "timestamp": 1565102758070,
     "user": {
      "displayName": "陳信榮",
      "photoUrl": "https://lh4.googleusercontent.com/-OFFdnL2yS4E/AAAAAAAAAAI/AAAAAAAABc8/1xp3cp3kugc/s64/photo.jpg",
      "userId": "09164636050182271119"
     },
     "user_tz": -480
    },
    "id": "LuqDcUhrY9vo",
    "outputId": "dd56543d-b0d9-4e38-a3ed-3ec1f503b91e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import keras\n",
      "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
      "from keras.layers import AveragePooling2D, Input, Flatten\n",
      "from keras.regularizers import l2\n",
      "from keras import backend as K\n",
      "from keras.models import Model\n",
      "\n",
      "def resnet_layer(inputs,\n",
      "                 num_filters=16,\n",
      "                 kernel_size=3,\n",
      "                 strides=1,\n",
      "                 activation='relu',\n",
      "                 batch_normalization=True,\n",
      "                 conv_first=True):\n",
      "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
      "    # Arguments\n",
      "        inputs (tensor): input tensor from input image or previous layer\n",
      "        num_filters (int): Conv2D number of filters\n",
      "        kernel_size (int): Conv2D square kernel dimensions\n",
      "        strides (int): Conv2D square stride dimensions\n",
      "        activation (string): activation name\n",
      "        batch_normalization (bool): whether to include batch normalization\n",
      "        conv_first (bool): conv-bn-activation (True) or\n",
      "            bn-activation-conv (False)\n",
      "    # Returns\n",
      "        x (tensor): tensor as input to the next layer\n",
      "    \"\"\"\n",
      "    conv = Conv2D(num_filters,\n",
      "                  kernel_size=kernel_size,\n",
      "                  strides=strides,\n",
      "                  padding='same',\n",
      "                  kernel_initializer='he_normal',\n",
      "                  kernel_regularizer=l2(1e-4))\n",
      "\n",
      "    x = inputs\n",
      "    if conv_first:\n",
      "        x = conv(x)\n",
      "        if batch_normalization:\n",
      "            x = BatchNormalization()(x)\n",
      "        if activation is not None:\n",
      "            x = Activation(activation)(x)\n",
      "    else:\n",
      "        if batch_normalization:\n",
      "            x = BatchNormalization()(x)\n",
      "        if activation is not None:\n",
      "            x = Activation(activation)(x)\n",
      "        x = conv(x)\n",
      "    return x\n",
      "\n",
      "def resnet(input_shape, depth=29, num_classes=10):\n",
      "    \"\"\"ResNet Version 2 Model builder [b]\n",
      "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
      "    bottleneck layer\n",
      "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
      "    Second and onwards shortcut connection is identity.\n",
      "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
      "    by a convolutional layer with strides=2, while the number of filter maps is\n",
      "    doubled. Within each stage, the layers have the same number filters and the\n",
      "    same filter map sizes.\n",
      "    Features maps sizes:\n",
      "    conv1  : 32x32,  16\n",
      "    stage 0: 32x32,  64\n",
      "    stage 1: 16x16, 128\n",
      "    stage 2:  8x8,  256\n",
      "    # Arguments\n",
      "        input_shape (tensor): shape of input image tensor\n",
      "        depth (int): number of core convolutional layers\n",
      "        num_classes (int): number of classes (CIFAR10 has 10)\n",
      "    # Returns\n",
      "        model (Model): Keras model instance\n",
      "    \"\"\"\n",
      "    if (depth - 2) % 9 != 0:\n",
      "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
      "    # Start model definition.\n",
      "    num_filters_in = 16\n",
      "    num_res_blocks = int((depth - 2) / 9)\n",
      "\n",
      "    inputs = Input(shape=input_shape)\n",
      "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
      "    x = resnet_layer(inputs=inputs,\n",
      "                     num_filters=num_filters_in,\n",
      "                     conv_first=True)\n",
      "\n",
      "    # Instantiate the stack of residual units\n",
      "    for stage in range(3):\n",
      "        for res_block in range(num_res_blocks):\n",
      "            activation = 'relu'\n",
      "            batch_normalization = True\n",
      "            strides = 1\n",
      "            if stage == 0:\n",
      "                num_filters_out = num_filters_in * 4\n",
      "                if res_block == 0:  # first layer and first stage\n",
      "                    activation = None\n",
      "                    batch_normalization = False\n",
      "            else:\n",
      "                num_filters_out = num_filters_in * 2\n",
      "                if res_block == 0:  # first layer but not first stage\n",
      "                    strides = 2    # downsample\n",
      "\n",
      "            # bottleneck residual unit\n",
      "            y = resnet_layer(inputs=x,\n",
      "                             num_filters=num_filters_in,\n",
      "                             kernel_size=1,\n",
      "                             strides=strides,\n",
      "                             activation=activation,\n",
      "                             batch_normalization=batch_normalization,\n",
      "                             conv_first=False)\n",
      "            y = resnet_layer(inputs=y,\n",
      "                             num_filters=num_filters_in,\n",
      "                             conv_first=False)\n",
      "            y = resnet_layer(inputs=y,\n",
      "                             num_filters=num_filters_out,\n",
      "                             kernel_size=1,\n",
      "                             conv_first=False)\n",
      "            if res_block == 0:\n",
      "                # linear projection residual shortcut connection to match\n",
      "                # changed dims\n",
      "                x = resnet_layer(inputs=x,\n",
      "                                 num_filters=num_filters_out,\n",
      "                                 kernel_size=1,\n",
      "                                 strides=strides,\n",
      "                                 activation=None,\n",
      "                                 batch_normalization=False)\n",
      "            x = keras.layers.add([x, y])\n",
      "\n",
      "        num_filters_in = num_filters_out\n",
      "\n",
      "    # Add classifier on top.\n",
      "    # v2 has BN-ReLU before Pooling\n",
      "    x = BatchNormalization()(x)\n",
      "    x = Activation('relu')(x)\n",
      "    x = AveragePooling2D(pool_size=8)(x)\n",
      "    y = Flatten()(x)\n",
      "    outputs = Dense(num_classes,\n",
      "                    activation='softmax',\n",
      "                    kernel_initializer='he_normal')(y)\n",
      "\n",
      "    # Instantiate model.\n",
      "    model = Model(inputs=inputs, outputs=outputs)\n",
      "    return model"
     ]
    }
   ],
   "source": [
    "!cat '/content/drive/My Drive/resnet_builder.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tPux7DBiZR8z"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/drive/My Drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fe4l8zeXHxYY"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from resnet_builder import resnet # 這是從 resnet_builder.py 中直接 import 撰寫好的 resnet 函數\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7972,
     "status": "ok",
     "timestamp": 1565102889742,
     "user": {
      "displayName": "陳信榮",
      "photoUrl": "https://lh4.googleusercontent.com/-OFFdnL2yS4E/AAAAAAAAAAI/AAAAAAAABc8/1xp3cp3kugc/s64/photo.jpg",
      "userId": "09164636050182271119"
     },
     "user_tz": -480
    },
    "id": "fxZ4vTMOZmHU",
    "outputId": "2b180c1e-f6bc-4afd-8c61-0a2e49f140a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 4s 0us/step\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# 讀取資料集並作前處理\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6765,
     "status": "ok",
     "timestamp": 1565102914403,
     "user": {
      "displayName": "陳信榮",
      "photoUrl": "https://lh4.googleusercontent.com/-OFFdnL2yS4E/AAAAAAAAAAI/AAAAAAAABc8/1xp3cp3kugc/s64/photo.jpg",
      "userId": "09164636050182271119"
     },
     "user_tz": -480
    },
    "id": "STmuwFEjZu0j",
    "outputId": "2e7642a3-c8e3-4b8c-db0d-a67501f1c074"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0806 14:48:29.460232 140486294206336 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0806 14:48:29.509088 140486294206336 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0806 14:48:29.517789 140486294206336 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W0806 14:48:29.567185 140486294206336 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0806 14:48:29.568824 140486294206336 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0806 14:48:32.465790 140486294206336 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0806 14:48:35.039275 140486294206336 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   272         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 64)   1088        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 64)   1088        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 64)   0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 16)   1040        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 16)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 64)   1088        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 64)   0           add_1[0][0]                      \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 16)   1040        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 16)   2320        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 16)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 64)   1088        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 64)   0           add_2[0][0]                      \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 64)   256         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 64)   4160        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 64)   256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 64)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 64)   36928       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 64)   256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 128)  8320        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 128)  8320        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 128)  0           conv2d_15[0][0]                  \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 128)  512         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 64)   8256        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 64)   256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 64)   36928       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 64)   256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 128)  8320        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 128)  0           add_4[0][0]                      \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 128)  512         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 64)   8256        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 64)   256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 64)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 64)   36928       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 64)   256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 128)  8320        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 128)  0           add_5[0][0]                      \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 128)  512         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 128)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 8, 8, 128)    16512       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 8, 8, 128)    512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 8, 8, 128)    0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 8, 8, 128)    147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 8, 8, 128)    512         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 8, 8, 128)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 8, 8, 256)    33024       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 8, 8, 256)    33024       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 256)    0           conv2d_25[0][0]                  \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 8, 8, 256)    1024        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 8, 8, 256)    0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 8, 8, 128)    32896       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 8, 8, 128)    512         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 8, 8, 128)    0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 8, 8, 128)    147584      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 8, 8, 128)    512         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 8, 8, 128)    0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 8, 8, 256)    33024       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 256)    0           add_7[0][0]                      \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 8, 8, 256)    1024        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 8, 8, 256)    0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 8, 8, 128)    32896       activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 8, 8, 128)    512         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 8, 8, 128)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 8, 8, 128)    147584      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 8, 8, 128)    512         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 8, 8, 128)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 8, 8, 256)    33024       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 256)    0           add_8[0][0]                      \n",
      "                                                                 conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 8, 8, 256)    1024        add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 8, 8, 256)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 256)    0           activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 256)          0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           2570        flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 849,002\n",
      "Trainable params: 843,786\n",
      "Non-trainable params: 5,216\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 建立 ResNet 模型\n",
    "model = resnet(input_shape=(32,32,3)) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1042907,
     "status": "ok",
     "timestamp": 1565103990851,
     "user": {
      "displayName": "陳信榮",
      "photoUrl": "https://lh4.googleusercontent.com/-OFFdnL2yS4E/AAAAAAAAAAI/AAAAAAAABc8/1xp3cp3kugc/s64/photo.jpg",
      "userId": "09164636050182271119"
     },
     "user_tz": -480
    },
    "id": "tXLcjkFQZ1vo",
    "outputId": "17d240ee-6608-4db7-b3fa-5d393c42ef50"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0806 14:49:09.738639 140486294206336 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0806 14:49:10.245233 140486294206336 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 43s 854us/step - loss: 1.9285 - acc: 0.4865 - val_loss: 1.7451 - val_acc: 0.5258\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 33s 665us/step - loss: 1.4304 - acc: 0.6410 - val_loss: 1.6251 - val_acc: 0.5627\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 33s 669us/step - loss: 1.2147 - acc: 0.7022 - val_loss: 1.5146 - val_acc: 0.5994\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 34s 675us/step - loss: 1.0674 - acc: 0.7488 - val_loss: 1.3864 - val_acc: 0.6246\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 34s 676us/step - loss: 0.9592 - acc: 0.7800 - val_loss: 1.5449 - val_acc: 0.6071\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 34s 679us/step - loss: 0.8618 - acc: 0.8146 - val_loss: 1.2317 - val_acc: 0.7094\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 34s 680us/step - loss: 0.7872 - acc: 0.8389 - val_loss: 1.2864 - val_acc: 0.7009\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 34s 682us/step - loss: 0.7255 - acc: 0.8604 - val_loss: 1.8514 - val_acc: 0.5626\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 34s 683us/step - loss: 0.6650 - acc: 0.8813 - val_loss: 1.4465 - val_acc: 0.6821\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 34s 684us/step - loss: 0.6290 - acc: 0.8935 - val_loss: 1.5960 - val_acc: 0.6763\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 34s 685us/step - loss: 0.5950 - acc: 0.9074 - val_loss: 1.3144 - val_acc: 0.7119\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 34s 687us/step - loss: 0.5636 - acc: 0.9185 - val_loss: 1.7289 - val_acc: 0.6422\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 34s 685us/step - loss: 0.5391 - acc: 0.9262 - val_loss: 1.5657 - val_acc: 0.6858\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 34s 686us/step - loss: 0.5284 - acc: 0.9301 - val_loss: 1.3755 - val_acc: 0.7305\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 34s 685us/step - loss: 0.5074 - acc: 0.9391 - val_loss: 1.8409 - val_acc: 0.6350\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 34s 685us/step - loss: 0.5042 - acc: 0.9391 - val_loss: 2.0783 - val_acc: 0.6527\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 34s 684us/step - loss: 0.4846 - acc: 0.9464 - val_loss: 2.0352 - val_acc: 0.6546\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 34s 687us/step - loss: 0.4835 - acc: 0.9469 - val_loss: 1.7896 - val_acc: 0.7003\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 34s 687us/step - loss: 0.4852 - acc: 0.9452 - val_loss: 1.8214 - val_acc: 0.6814\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 34s 687us/step - loss: 0.4646 - acc: 0.9527 - val_loss: 1.7884 - val_acc: 0.6736\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 34s 688us/step - loss: 0.4727 - acc: 0.9494 - val_loss: 2.0042 - val_acc: 0.6486\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 34s 685us/step - loss: 0.4577 - acc: 0.9553 - val_loss: 2.2187 - val_acc: 0.6507\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 34s 688us/step - loss: 0.4526 - acc: 0.9562 - val_loss: 1.4964 - val_acc: 0.7417\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 35s 694us/step - loss: 0.4568 - acc: 0.9548 - val_loss: 2.3561 - val_acc: 0.6293\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 34s 688us/step - loss: 0.4545 - acc: 0.9554 - val_loss: 1.7226 - val_acc: 0.6936\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 34s 689us/step - loss: 0.4485 - acc: 0.9573 - val_loss: 2.0226 - val_acc: 0.6736\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 34s 690us/step - loss: 0.4428 - acc: 0.9590 - val_loss: 2.2625 - val_acc: 0.6548\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 34s 687us/step - loss: 0.4379 - acc: 0.9607 - val_loss: 1.8307 - val_acc: 0.6856\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 34s 688us/step - loss: 0.4387 - acc: 0.9593 - val_loss: 1.8172 - val_acc: 0.7114\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 34s 688us/step - loss: 0.4438 - acc: 0.9575 - val_loss: 2.5733 - val_acc: 0.6135\n",
      "Test loss: 2.5733104188919067\n",
      "Test accuracy: 0.6135\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128 # batch 的大小，如果出現 OOM error，請降低這個值\n",
    "num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n",
    "epochs = 30 # 訓練整個資料集共 30個循環\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Day100_transfer_learning_HW.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
