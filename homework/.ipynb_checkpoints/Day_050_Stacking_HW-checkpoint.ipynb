{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 作業 : (Kaggle)鐵達尼生存預測\n",
    "***\n",
    "- 分數以網站評分結果為準, 請同學實際將提交檔(*.csv)上傳試試看  \n",
    "https://www.kaggle.com/c/titanic/submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [作業目標]\n",
    "- 試著模仿範例寫法, 在鐵達尼生存預測中, 觀查堆疊泛化 (Stacking) 的寫法與效果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [作業重點]\n",
    "- 完成堆疊泛化的寫作, 看看提交結果, 想想看 : 分類與回歸的堆疊泛化, 是不是也與混合泛化一樣有所不同呢?(In[14])  \n",
    "如果可能不同, 應該怎麼改寫會有較好的結果?  \n",
    "- Hint : 請參考 mlxtrend 官方網站 StackingClassifier 的頁面說明 : Using Probabilities as Meta-Features\n",
    "http://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 做完特徵工程前的所有準備 (與前範例相同)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy, time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import display\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data_path = 'data/'\n",
    "df_train = pd.read_csv(data_path + 'titanic_train.csv')\n",
    "df_test = pd.read_csv(data_path + 'titanic_test.csv')\n",
    "\n",
    "train_Y = df_train['Survived']\n",
    "ids = df_test['PassengerId']\n",
    "df_train = df_train.drop(['PassengerId', 'Survived'] , axis=1)\n",
    "df_test = df_test.drop(['PassengerId'] , axis=1)\n",
    "df = pd.concat([df_train,df_test])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 檢查 DataFrame 空缺值的狀態\n",
    "def na_check(df_data):\n",
    "    data_na = (df_data.isnull().sum() / len(df_data)) * 100\n",
    "    data_na = data_na.drop(data_na[data_na == 0].index).sort_values(ascending=False)\n",
    "    missing_data = pd.DataFrame({'Missing Ratio' :data_na})\n",
    "    display(missing_data.head(10))\n",
    "na_check(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下 In[3]~In[10] 只是鐵達尼預測中的一組特徵工程, 並以此組特徵工程跑參數, 若更換其他特徵工程, In[10]的參數需要重新跑\n",
    "# Sex : 直接轉男 0 女 1\n",
    "df[\"Sex\"] = df[\"Sex\"].map({\"male\": 0, \"female\":1})\n",
    "# Fare : 用 log 去偏態, 0 則直接取 0\n",
    "df[\"Fare\"] = df[\"Fare\"].map(lambda i: np.log(i) if i > 0 else 0)\n",
    "# Age : 缺值用中位數補\n",
    "df[\"Age\"] = df[\"Age\"].fillna(df['Age'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title 的 特徵工程 : 將各種頭銜按照類型分類, 最後取 One Hot\n",
    "df_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in df[\"Name\"]]\n",
    "df[\"Title\"] = pd.Series(df_title)\n",
    "df[\"Title\"] = df[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "df[\"Title\"] = df[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 , \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \"Rare\":3})\n",
    "df[\"Title\"] = df[\"Title\"].astype(int)\n",
    "df = pd.get_dummies(df, columns = [\"Title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新建:家庭大小 (Fsize)特徵, 並依照大小分別建獨立欄位\n",
    "df[\"Fsize\"] = df[\"SibSp\"] + df[\"Parch\"] + 1\n",
    "df['Single'] = df['Fsize'].map(lambda s: 1 if s == 1 else 0)\n",
    "df['SmallF'] = df['Fsize'].map(lambda s: 1 if  s == 2  else 0)\n",
    "df['MedF'] = df['Fsize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\n",
    "df['LargeF'] = df['Fsize'].map(lambda s: 1 if s >= 5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ticket : 如果不只是數字-取第一個空白之前的字串(去除'.'與'/'), 如果只是數字-設為'X', 最後再取 One Hot\n",
    "Ticket = []\n",
    "for i in list(df.Ticket):\n",
    "    if not i.isdigit() :\n",
    "        Ticket.append(i.replace(\".\",\"\").replace(\"/\",\"\").strip().split(' ')[0])\n",
    "    else:\n",
    "        Ticket.append(\"X\")        \n",
    "df[\"Ticket\"] = Ticket\n",
    "df = pd.get_dummies(df, columns = [\"Ticket\"], prefix=\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cabib 依照第一碼分類, 再取 One Hot\n",
    "df[\"Cabin\"] = pd.Series([i[0] if not pd.isnull(i) else 'X' for i in df['Cabin'] ])\n",
    "df = pd.get_dummies(df, columns = [\"Cabin\"], prefix=\"Cabin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embarked, Pclass 取 One Hot\n",
    "df = pd.get_dummies(df, columns = [\"Embarked\"], prefix=\"Em\")\n",
    "df[\"Pclass\"] = df[\"Pclass\"].astype(\"category\")\n",
    "df = pd.get_dummies(df, columns = [\"Pclass\"], prefix=\"Pc\")\n",
    "\n",
    "# 捨棄 Name 欄位\n",
    "df.drop(labels = [\"Name\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_check(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將資料最大最小化\n",
    "df = MinMaxScaler().fit_transform(df)\n",
    "\n",
    "# 將前述轉換完畢資料 df , 重新切成 train_X, test_X\n",
    "train_num = train_Y.shape[0]\n",
    "train_X = df[:train_num]\n",
    "test_X = df[train_num:]\n",
    "\n",
    "# 使用三種模型 : 邏輯斯迴歸 / 梯度提升機 / 隨機森林, 參數使用 Random Search 尋找\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "lr = LogisticRegression(tol=0.001, penalty='l2', fit_intercept=True, C=1.0)\n",
    "gdbt = GradientBoostingClassifier(tol=100, subsample=0.75, n_estimators=250, max_features=20,\n",
    "                                  max_depth=6, learning_rate=0.03)\n",
    "rf = RandomForestClassifier(n_estimators=100, min_samples_split=2, min_samples_leaf=1, \n",
    "                            max_features='sqrt', max_depth=6, bootstrap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 線性迴歸預測檔 (結果有部分隨機, 請以 Kaggle 計算的得分為準, 以下模型同理)\n",
    "lr.fit(train_X, train_Y)\n",
    "lr_pred = lr.predict_proba(test_X)[:,1]\n",
    "sub = pd.DataFrame({'PassengerId': ids, 'Survived': lr_pred})\n",
    "sub['Survived'] = sub['Survived'].map(lambda x:1 if x>0.5 else 0) \n",
    "sub.to_csv('titanic_lr.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 梯度提升機預測檔 \n",
    "gdbt.fit(train_X, train_Y)\n",
    "gdbt_pred = gdbt.predict_proba(test_X)[:,1]\n",
    "sub = pd.DataFrame({'PassengerId': ids, 'Survived': gdbt_pred})\n",
    "sub['Survived'] = sub['Survived'].map(lambda x:1 if x>0.5 else 0) \n",
    "sub.to_csv('titanic_gdbt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 隨機森林預測檔\n",
    "rf.fit(train_X, train_Y)\n",
    "rf_pred = rf.predict_proba(test_X)[:,1]\n",
    "sub = pd.DataFrame({'PassengerId': ids, 'Survived': rf_pred})\n",
    "sub['Survived'] = sub['Survived'].map(lambda x:1 if x>0.5 else 0) \n",
    "sub.to_csv('titanic_rf.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 作業\n",
    "* 分類預測的集成泛化, 也與回歸的很不一樣  \n",
    "既然分類的 Blending 要變成機率, 才比較容易集成,\n",
    "那麼分類的 Stacking 要讓第一層的模型輸出機率當特徵, 應該要怎麼寫呢?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "meta_estimator = GradientBoostingClassifier(tol=100, subsample=0.70, n_estimators=50, \n",
    "                                           max_features='sqrt', max_depth=4, learning_rate=0.3)\n",
    "\"\"\"\n",
    "Your Code Here\n",
    "\"\"\"\n",
    "stacking = StackingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking.fit(train_X, train_Y)\n",
    "stacking_pred = stacking.predict(test_X)\n",
    "sub = pd.DataFrame({'PassengerId': ids, 'Survived': stacking_pred})\n",
    "sub.to_csv('titanic_stacking.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
